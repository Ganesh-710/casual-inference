{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install econml","metadata":{"execution":{"iopub.status.busy":"2022-04-29T13:24:27.318126Z","iopub.execute_input":"2022-04-29T13:24:27.318535Z","iopub.status.idle":"2022-04-29T13:24:50.680423Z","shell.execute_reply.started":"2022-04-29T13:24:27.318422Z","shell.execute_reply":"2022-04-29T13:24:50.679361Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# External Libaries required for the majority of the assignment, more to be added as more tasks are completed \nfrom econml.metalearners import XLearner\nfrom sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom sklearn.model_selection import GridSearchCV\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport scipy.stats as st\nimport matplotlib.pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2022-04-29T13:24:50.682975Z","iopub.execute_input":"2022-04-29T13:24:50.683326Z","iopub.status.idle":"2022-04-29T13:25:00.846197Z","shell.execute_reply.started":"2022-04-29T13:24:50.683281Z","shell.execute_reply":"2022-04-29T13:25:00.845561Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Metrics:\n    \n    def pehe(self,effect_true, effect_pred):\n        \"\"\"\n        Precision in Estimating the Heterogeneous Treatment Effect (PEHE)\n        :param effect_true: true treatment effect value\n        :param effect_pred: predicted treatment effect value\n        :return: PEHE\n        \"\"\"\n        return np.abs(np.mean(effect_pred) - np.mean(effect_true))\n\n    def abs_ate(self,effect_true, effect_pred):\n        \"\"\"\n        Absolute error for the Average Treatment Effect (ATE)\n        :param effect_true: true treatment effect value\n        :param effect_pred: predicted treatment effect value\n        :return: absolute error on ATE\n        \"\"\"\n        return np.sqrt(np.mean((effect_true - effect_pred)**2))\n    @staticmethod\n    def abs_att(effect_pred, yf, t, e):\n        \"\"\"\n        Absolute error for the Average Treatment Effect on the Treated\n        :param effect_pred: predicted treatment effect value\n        :param yf: factual (observed) outcome\n        :param t: treatment status (treated/control)\n        :param e: whether belongs to the experimental group\n        :return: absolute error on ATT\n        \"\"\"\n        att_true = np.mean(yf[t > 0]) - np.mean(yf[(1 - t + e) > 1])\n        att_pred = np.mean(effect_pred[(t + e) > 1])\n\n        return np.abs(att_pred - att_true)\n    @staticmethod\n    def policy_risk(effect_pred, yf, t, e):\n        \"\"\"\n        Computes the risk of the policy defined by predicted effect\n        :param effect_pred: predicted treatment effect value\n        :param yf: factual (observed) outcome\n        :param t: treatment status (treated/control)\n        :param e: whether belongs to the experimental group\n        :return: policy risk\n        \"\"\"\n        # Consider only the cases for which we have experimental data (i.e., e > 0)\n        t_e = t[e > 0]\n        yf_e = yf[e > 0]\n        effect_pred_e = effect_pred[e > 0]\n\n        if np.any(np.isnan(effect_pred_e)):\n            return np.nan\n\n        policy = effect_pred_e > 0.0\n        treat_overlap = (policy == t_e) * (t_e > 0)\n        control_overlap = (policy == t_e) * (t_e < 1)\n\n        if np.sum(treat_overlap) == 0:\n            treat_value = 0\n        else:\n            treat_value = np.mean(yf_e[treat_overlap])\n\n        if np.sum(control_overlap) == 0:\n            control_value = 0\n        else:\n            control_value = np.mean(yf_e[control_overlap])\n\n        pit = np.mean(policy)\n        policy_value = pit * treat_value + (1.0 - pit) * control_value\n\n        return 1.0 - policy_value\nmetrics = Metrics()","metadata":{"execution":{"iopub.status.busy":"2022-04-29T13:25:00.847511Z","iopub.execute_input":"2022-04-29T13:25:00.848310Z","iopub.status.idle":"2022-04-29T13:25:00.862887Z","shell.execute_reply.started":"2022-04-29T13:25:00.848274Z","shell.execute_reply":"2022-04-29T13:25:00.861706Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data Exploration, Preprocessing and Modelling","metadata":{}},{"cell_type":"code","source":"# x =  Background Variables, t = Treatment Variable (Support or no support), yf = Outcome Variable (Factual)\n# ycf = Outcome Variable (Counterfactual), ite = individual treatment effect\ndata = np.load('../input/datasetihdp/ihdp.npz')\nfor f in data.files:\n  print(f'{f}: {data[f].shape}')","metadata":{"execution":{"iopub.status.busy":"2022-04-29T13:25:00.864850Z","iopub.execute_input":"2022-04-29T13:25:00.865255Z","iopub.status.idle":"2022-04-29T13:25:00.961842Z","shell.execute_reply.started":"2022-04-29T13:25:00.865225Z","shell.execute_reply":"2022-04-29T13:25:00.961192Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_x,df_t,df_yf,df_ycf,df_ite = data['x'],data['t'],data['yf'], data['ycf'],data['ite']\nprint('ATE : ', np.mean(df_ite))","metadata":{"execution":{"iopub.status.busy":"2022-04-29T13:25:00.963096Z","iopub.execute_input":"2022-04-29T13:25:00.963513Z","iopub.status.idle":"2022-04-29T13:25:00.971993Z","shell.execute_reply.started":"2022-04-29T13:25:00.963482Z","shell.execute_reply":"2022-04-29T13:25:00.971346Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"IHDP_x,IHDP_t,IHDP_yf,IHDP_ycf, IHDP_ite = pd.DataFrame(df_x),pd.DataFrame(df_t), pd.DataFrame(df_yf), pd.DataFrame(df_ycf), pd.DataFrame(df_ite)\nIHDP_x.info()","metadata":{"execution":{"iopub.status.busy":"2022-04-29T13:25:00.973447Z","iopub.execute_input":"2022-04-29T13:25:00.973874Z","iopub.status.idle":"2022-04-29T13:25:01.006262Z","shell.execute_reply.started":"2022-04-29T13:25:00.973843Z","shell.execute_reply":"2022-04-29T13:25:01.005629Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There appears to be no missing data or non-numerical values from the IHDP dataset therefore no preprocessing is needed in regards to encoding and filling Nan rows.","metadata":{}},{"cell_type":"code","source":"IHDP_x.describe().T","metadata":{"execution":{"iopub.status.busy":"2022-04-29T13:25:01.007565Z","iopub.execute_input":"2022-04-29T13:25:01.007775Z","iopub.status.idle":"2022-04-29T13:25:01.093717Z","shell.execute_reply.started":"2022-04-29T13:25:01.007750Z","shell.execute_reply":"2022-04-29T13:25:01.093070Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.pairplot(data=IHDP_x)","metadata":{"execution":{"iopub.status.busy":"2022-04-29T13:25:01.094585Z","iopub.execute_input":"2022-04-29T13:25:01.094905Z","iopub.status.idle":"2022-04-29T13:27:52.911199Z","shell.execute_reply.started":"2022-04-29T13:25:01.094878Z","shell.execute_reply":"2022-04-29T13:27:52.907691Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bins=20\nfig, axs = plt.subplots(1, 5, figsize=(16, 4))\naxs[0].hist(df_x, bins=bins)\naxs[1].hist(df_t, bins=bins)\naxs[2].hist(df_yf, bins=bins)\naxs[3].hist(df_ycf, bins=bins)\naxs[4].hist(df_ite, bins=bins)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-29T13:27:52.914544Z","iopub.execute_input":"2022-04-29T13:27:52.914896Z","iopub.status.idle":"2022-04-29T13:27:54.543278Z","shell.execute_reply.started":"2022-04-29T13:27:52.914853Z","shell.execute_reply":"2022-04-29T13:27:54.542461Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"IHDP_x.hist(bins=25,figsize=(12,10))","metadata":{"execution":{"iopub.status.busy":"2022-04-29T13:27:54.547135Z","iopub.execute_input":"2022-04-29T13:27:54.547790Z","iopub.status.idle":"2022-04-29T13:27:58.835171Z","shell.execute_reply.started":"2022-04-29T13:27:54.547757Z","shell.execute_reply":"2022-04-29T13:27:58.834345Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"limit = 150\nfig, axs = plt.subplots(1, 2, figsize=(16, 4))\n# These scatterplots have only been made via factual outcomes \n# More scatterplots could be made to model the counterfactual outcomes\naxs[0].scatter(df_x[:, 0].reshape(-1, 1)[df_t == 1][:limit]\n               , df_yf[df_t == 1][:limit], label = \"Treated\")\naxs[0].scatter(df_x[:, 0].reshape(-1, 1)[df_t == 0][:limit]\n               , df_yf[df_t == 0][:limit], label = \"Control\")\naxs[1].scatter(df_x[:, 0].reshape(-1, 1)[df_t == 1][:limit]\n               , df_ycf[df_t == 1][:limit], label = \"Treated\")\naxs[1].scatter(df_x[:, 0].reshape(-1, 1)[df_t == 0][:limit]\n               , df_ycf[df_t == 0][:limit], label = \"Control\")\naxs[0].legend(ncol=2)\naxs[1].legend(ncol=2)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-29T13:27:58.836673Z","iopub.execute_input":"2022-04-29T13:27:58.837199Z","iopub.status.idle":"2022-04-29T13:27:59.304974Z","shell.execute_reply.started":"2022-04-29T13:27:58.837166Z","shell.execute_reply":"2022-04-29T13:27:59.304287Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"limit = 150\nfig, axs = plt.subplots(1, 2, figsize=(16, 4))\n# These scatterplots have only been made via factual outcomes \n# More scatterplots could be made to model the counterfactual outcomes\naxs[0].scatter(df_x[:, 1].reshape(-1, 1)[df_t == 1][:limit]\n               , df_yf[df_t == 1][:limit], label = \"Treated\")\naxs[0].scatter(df_x[:, 1].reshape(-1, 1)[df_t == 0][:limit]\n               , df_yf[df_t == 0][:limit], label = \"Control\")\naxs[1].scatter(df_x[:, 1].reshape(-1, 1)[df_t == 1][:limit]\n               , df_ycf[df_t == 1][:limit], label = \"Treated\")\naxs[1].scatter(df_x[:, 1].reshape(-1, 1)[df_t == 0][:limit]\n               , df_ycf[df_t == 0][:limit], label = \"Control\")\naxs[0].legend(ncol=2)\naxs[1].legend(ncol=2)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-29T13:27:59.306156Z","iopub.execute_input":"2022-04-29T13:27:59.306832Z","iopub.status.idle":"2022-04-29T13:27:59.758308Z","shell.execute_reply.started":"2022-04-29T13:27:59.306792Z","shell.execute_reply":"2022-04-29T13:27:59.757760Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(18, 10))\nheatmap = sns.heatmap(IHDP_x.corr(), vmin=-1, vmax=1, annot=True)\nheatmap.set_title('Correlation Heatmap', fontdict={'fontsize':12}, pad=12);","metadata":{"execution":{"iopub.status.busy":"2022-04-29T13:27:59.759685Z","iopub.execute_input":"2022-04-29T13:27:59.760136Z","iopub.status.idle":"2022-04-29T13:28:02.958279Z","shell.execute_reply.started":"2022-04-29T13:27:59.760087Z","shell.execute_reply":"2022-04-29T13:28:02.957552Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bins=20\nplt.figsize=(16, 4)\nplt.hist(df_t, bins=bins, color = \"orange\")\nplt.title(\"IHDP Control and treatment Distribution\", fontsize=12, fontweight=\"bold\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-29T13:28:02.959569Z","iopub.execute_input":"2022-04-29T13:28:02.960319Z","iopub.status.idle":"2022-04-29T13:28:03.208265Z","shell.execute_reply.started":"2022-04-29T13:28:02.960277Z","shell.execute_reply":"2022-04-29T13:28:03.207448Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Standardizing and spliting\n","metadata":{}},{"cell_type":"code","source":"x_train, x_test, t_train, t_test, yf_train, yf_test, ite_train, ite_test = train_test_split(df_x, df_t, df_yf, df_ite, test_size=0.2)","metadata":{"execution":{"iopub.status.busy":"2022-04-29T13:28:03.209463Z","iopub.execute_input":"2022-04-29T13:28:03.209791Z","iopub.status.idle":"2022-04-29T13:28:03.215890Z","shell.execute_reply.started":"2022-04-29T13:28:03.209755Z","shell.execute_reply":"2022-04-29T13:28:03.214827Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"temp_X_IHDP = pd.DataFrame(x_train)\ntemp_X_test_IHDP = pd.DataFrame(x_test)\n#temp_X_IHDP.head()\ntemp_yf_IHDP = pd.DataFrame(yf_train)\n#temp_yf_IHDP.head()\n#[temp_X_IHDP[cols].unique() for cols in temp_X_IHDP]","metadata":{"execution":{"iopub.status.busy":"2022-04-29T13:28:03.670275Z","iopub.execute_input":"2022-04-29T13:28:03.670669Z","iopub.status.idle":"2022-04-29T13:28:03.679068Z","shell.execute_reply.started":"2022-04-29T13:28:03.670570Z","shell.execute_reply":"2022-04-29T13:28:03.678410Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Scaling the data","metadata":{}},{"cell_type":"markdown","source":"Columns 0-5 all require conventional scaling, however the remainder are binary and so do not. We also know that our outcome column requires Standard scaling based on previous modelling.","metadata":{}},{"cell_type":"code","source":"# IHDP\n# Scale the first 6 columns of our features (all non binary)\ntemp_X_IHDP.iloc[:, 0:5] = StandardScaler().fit_transform(temp_X_IHDP.iloc[:, 0:5])\ntemp_X_test_IHDP.iloc[:, 0:5] = StandardScaler().fit_transform(temp_X_test_IHDP.iloc[:, 0:5])\n# Scale our outcomes column \nyf_train_Stan = StandardScaler().fit_transform(temp_yf_IHDP) \n#temp_X_IHDP.head()\nx_train_Stan = temp_X_IHDP.to_numpy()\nx_test_Stan = temp_X_test_IHDP.to_numpy()","metadata":{"execution":{"iopub.status.busy":"2022-04-29T13:28:03.679940Z","iopub.execute_input":"2022-04-29T13:28:03.680841Z","iopub.status.idle":"2022-04-29T13:28:03.700454Z","shell.execute_reply.started":"2022-04-29T13:28:03.680805Z","shell.execute_reply":"2022-04-29T13:28:03.699587Z"},"trusted":true},"execution_count":null,"outputs":[]}]}